# 08 속도 제한 서비스 설계

속도 제한(Rate limiting)은 소비자가 API 엔드포인트에 요청할 수 있는 속도를 정의한다.  
속도 제한은 특히 봇과 같은 클라이언트의 의도하지 않거나 악의적인 과도한 사용을 방지한다.  

이러한 의도하지 않은 과도한 사용은 '시끄러운 이웃' 문제를 일으킨다.  

- DDos
- 무차별 대입 공격(Brute force attack)
- 웹 스크래핑


## 8.1 속도 제한 서비스의 대안과 그것이 실현 불가능한 이유

트래픽 급증이 감지될 때 새 호스트를 추가하는 과정이 너무 느릴 수 있다.  

로드 밸런서는 각 호스트로 보내는 요청 수를 제한할 수 있다.  

속도 제한기는 보통 429 Too Many Requests를 반환할 수 있으나, 특정 요청이 악의적이라고 확신한다면 다음 옵션 중 하나를 선택할 수 있다.  

- 요청을 버리고 응답을 반환하지 않아 공격자가 서비스에 장애가 발생했다고 생각하게 한다.
- 사용자를 섀도우 밴해서 200을 반환하되, 빈 응답이나 오해의 소지가 있는 응답을 보낸다.

사용자의 요청을 같은 호스트로 라우팅하는 고정 세션을 위해서는 7계층 로드 밸런서가 필요한데, 이는 비용과 복잡성을 증가시킨다.  


## 8.2 속도 제한을 하지 말아야 할 때

속도 제한이 모든 종류의 클라이언트 과다 사용에 적절한 해결책은 아니다.  


## 8.3 기능적 요구사항

- 속도 제한은 각 서비스에서 독립적이다.
- 사용자는 엔드포인트당 하나씩 여러 개의 속도 제한을 설정할 수 있다.
- 사용자는 어떤 사용자가 속도 제한이 됐는지, 언제 시작되고 끝났는지 볼 수 있어야 한다.
- 모든 요청을 로깅해야 하는지 면접관과 논의할 수 있다.
- 후속 조치와 분석을 위해서는 속도가 제한된 요청자를 로깅해야 한다.


## 8.4 비기능적 요구사항

속도 제한은 서비스 가용성에 필수적이지 않으므로 고가용성과 내결함성을 트레이드오프할 수 있다.  

### 8.4.1 확장성

서비스는 일일 수십억 건의 요청으로 확장할 수 있어야 한다.  

10초 이내에 100만에서 1,000만 명 이상의 사용자가 있을지에 대해 면접관과 논의할 수 있다.  
전체 저장 공간 요구사항은 `100(속데 제한이 필요한 서비스 수) * 64(타임스탬프 용량) * 101 * 1,000만(사용자) = 808GB`이다. 


### 8.4.2 성능

속도 제한기 요청의 응답 시간이 사용자 요청의 응답 시간에 추가된다.  
따라서 서비스는 매우 낮은 지연 시간이 필요하며, P99가 100ms여야 할 것이다.  


### 8.4.3 복잡성

서비스는 조직의 다른 많은 서비스가 사용하는 공유 서비스가 될 것이다.  
설계는 버그와 중단의 위험을 최소화하고, 문제 해결을 돕고, 속도 제한기로써 단일 기능에 집중할 수 있게 하며, 비용을 최소화하려면 단순해야 한다.


### 8.4.4 보안과 프라이버시

다른 서비스의 요청을 위조해 속도를 제한하는 등의 방식으로 속도 제한기를 공격하려 할 수 있다.  


### 8.4.5 가용성과 내결함성

고가용성이나 내결함성은 필요하지 않을 수 있다.  


### 8.4.6 정확성

사용자 경험 저하를 방지하려면 과도한 클라이언트를 잘못 식별해 속도를 제한해서는 안 된다.  


### 8.4.7 일관성

몇 초간의 불일치는 허용될 수 있다.  
로그 분석을 수행할 때도 최종 일관성이 허용된다.  
강한 일관성 대신 최종 일고나성을 사용하면 더 단순하고 저렴한 설계가 가능하다.  


## 8.5 사용자와 스토리가 필요한 서비스 구성 요소

속도 제한 요청에는 사용자 ID와 사용자 서비스 ID가 필수로 포함된다.  
속도 제한이 각 사용자 서비스에서 독립적이므로 ID 형식은 각 사용자 서비스에 특화될 수 있다.  

속도 제한기는 사용자 ID, 사용자 ID 데이터를 60초 동안 저장해야 한다.  
이는 사용자의 요청 속도가 속도 제한보다 높은지 판단하기 위해 이 데이터를 사용해야 하기 때문이다.  

로그에는 일관성과 지연 시간이 요구되지 않으므로 HDFS와 같은 최종 일관성 저장소에 로그를 저장할 수 있다.  


## 8.6 고수준 아키텍처

전체 지연 시간을 줄이려면 각 단계 스레드를 분기하거나 공통 스레드 풀의 스레드를 사용해 단계를 병렬로 수행할 수 있다.  

백엔드는 읽기/SELECT 쿼리만 팔로워 노드에 수행해야 한다.  

규칙이 자주 변경되지 않을 것으로 예상되므로 규칙 서비스에 레디스 캐시를 추가해 읽기 성능을 더욱 향상시킬 수 있다.  

> API 게이트웨이에서 Rate limiting을 수행해야하는게 아닌지?  
> 백엔드 뒷단에 위치할 경우 결국 모든 트래픽을 백엔드가 받아야된다는 의미인데, 백엔드 뒷단에서 수행하도록 설계한 이유를 이해하지 못 함


