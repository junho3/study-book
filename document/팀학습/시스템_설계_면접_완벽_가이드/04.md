# 04 데이터베이스 확장

## 4.1 저장 서비스의 이해

저장 서비스는 상태 저장 서비스다.  
상태 비저장 서비스와 비교해 상태 저장 서비스는 일관성을 보장하기 위한 메커니즘이 있으며, 데이터 손실을 피하려면 복제가 필요하다.  
상태 저장 서비스는 강한 일관성을 위해 팍소스와 같은 메커니즘을 선택하거나 최종 일관성 메커니즘을 선택할 수 있다.  

강한 일관성에서는 모든 접근이 모든 병렬 프로세스, 노드, 프로세서에서 동일한 순서로 보인다.  
따라서 하나의 일관된 상태만 관찰할 수 있다.  


## 4.2 데이터베이스 사용 결정

면접 중에는 특정 접근 방식을 선호할 수 있고 선호도를 언급할 수 있지만, 모든 관련 요인을 설명하고 다른 사람의 읙녀을 고려할 수 있어야 한다는 점을 기억해야 한다.  

- 객체 용량
- 읽기,쓰기 비율
- 객체 덮어쓰기나 교체 비율


## 4.3 복제

- 복제(Replication)
- 분할: 단일 노드
- 샤딩: 여러 노드

### 4.3.1 복제본 분산

샤딩의 주요 트레이드오프는 샤드 위치키를 추적해야 하는 복잡성 증가다.  

### 4.3.2 단일 리더 복제

단일 리더 복제는 쓰기가 아닌 읽기 확장에 관한 것이다.  
SQL 서비스는 ACID 일관성을 잃는다.  

단일 노드는 팔로워와 공유할 수 있는 처리량에 제한이 있으므로 팔로워의 최대 수를 제한하며, 이는 다시 읽기 확장성을 제한한다.  

또 다른 제한 사항은 팔로워 쓰기 복제에 시간이 걸리므로 최종 일관성이 있다는 점이다.  

#### 단일 리더 복제를 확장하기 위한 좋은 방법: 애플리케이션 계층의 쿼리 로직

데이터베이스 크기를 줄일 수 없지만 SQL을 계속 사용하고 싶다면, 가능한 방법은 데이터를 여러 SQL 데이터베이스로 나누는 것이다.  

단일 테이블을 두 개 이상의 데이터베이스로 분할해야 한다면 애플리케이션은 여러 데이터베이스를 쿼리하고 결과를 결합해야 한다.  


### 4.3.3 다중 리더 복제

여러 노드가 리더로 지정되며 모든 리더에서 쓰기를 수행할 수 있다.  
단일 리더 복제에는 없는 경쟁 조건을 처리해야 한다.  

#### 일관성 문제와 접근 방식

이러한 복제는 순서가 중요한 작업에서 일관성 문제와 경쟁 조건 문제를 야기한다.  

같은 소스와 주기적으로 동기화되는 서버 시간이라도 몇 밀리초 이상 차이가 난다.  

일반적으로 일관성 요구사항을 유연하게 조정할 방법을 찾아야 한다.  
모든 사용자에 대해 일관성을 유지해야 하는 데이터의 양을 최소화하는 접근 방식을 찾아야 한다.  


### 4.3.4 리더 없는 복제

읽기와 쓰기는 어느 노드에서나 일어날 수 있다.  
데이터베이스에 n개의 노드가 있고 읽기와 쓰기 모두 `n/2 + 1`개 노드의 정족 수를 가진다면 일관성이 보장된다는 점을 쉽게 추론할 수 있다.  

빠른 쓰기가 필요하다면 낮은 쓰기 정족수와 높은 읽기 정족수를 설정하고, 빠른 읽기가 필요할 때는 그 반대로 한다.  

- 카산드라
- 다이나모
- 리악
- 볼드모트


### 4.3.5 HDFS 복제

HDFS 클러스터는 활성 네임노드, 수동(백업) 네임노드, 여러 데이터노드로 구성된다.  

- 네임노드
  - 파일과 디렉터리 열고, 닫기
  - 이름 바꾸기
  - 블록을 데이터노드에 매핑
- 데이터노드
  - 파일 시스템 클라이언트의 읽기와 쓰기 요청 처리
  - 네임노드의 지시에 따라 블록 생성, 삭제, 복제 수행

HDFS는 테이블을 디렉터리에 하나 이상의 파일로 저장한다.  
각 파일은 블록으로 나뉘어 데이터노드에 분산된다.  

HDFS는 추가 작업만 전용으로 하며 UPDATE나 DELETE 작업을 지원하지 않는다.  


### 4.3.6 추가 읽을거리


## 4.4 샤딩된 데이터베이스로 저장 용량 확장하기

오래된 데이터를 보존해야 한다면 HDFS나 카산드라와 같은 샤딩된 스토리지에 저장해야 한다.  

다른 접근 방식은 소비자의 기기나 브라우저 쿠키, 로컬스토리지에 데이터를 저장하는 것이다.  

### 4.4.1 샤딩된 RDBMS

- JOIN 쿼리가 훨씬 느려진다.
- 집계 작업에는 데이터베이스와 애플리케이션이 모두 관여한다.


## 4.5 이벤트 집계하기

샘플링과 집계는 데이터베이스 쓰기 빈도를 줄이는 일반적인 기법이다.  

이벤트 집계는 여러 이벤트를 단일 이벤트로 집계/결합하는 것이다.  
따라서 여러 번의 데이터베이스 쓰기 대신 단 한번의 데이터베이스 쓰기만 발생한다.  
개별 이벤트의 정확한 타임스탬프가 중요하지 않다면 집계를 고려할 수 있다.  

집계는 스트리밍 파이프라인을 사용해 구현할 수 있다.  

### 4.5.1 단일 계층 집계

각 호스트는 메모리에 해시 테이블을 갖고 있어 해당 테이블에서 이 개수를 집계할 수 있다.  
각 호스트는 주기적 또는 메모리가 부족해질 때 중 더 빠른 시점에 개수를 데이터베이스에 기록할 수 있다.  

### 4.5.2 다중 계층 집계

각 계층의 호스트는 이전 계층의 상위 호스트로부터 이벤트를 집계할 수 있다.  
최종 계층에서 원하는 수의 호스트에 다다를 때까지 각 계층의 호스트 수를 점진적으로 줄일 수 있다.  
최종 계츠응ㄴ 데이터베이스에 기록한다.  

집계의 주요 트레이드오프는 최종 일관성과 증가된 복잡성이다.  

### 4.5.3 분할

분할에는 7계층 로드 밸런서가 필요하다.  

이벤트 트래픽은 정규 분포를 따를 것으로 예상할 수 있으며, 이는 특정 파티션이 불균형적으로 높은 트래픽을 받게 됨을 의미한다.  
파티션 별 호스트 수 외에도 트래픽을 균등하게 분산하려면 파티션 수와 범위를 조정할 수 있다.  

### 4.5.4 대규모 키 공간 처리하기

특정 계층의 결합된 키 공간이 다음 계층에서 메모리 오버플로를 일으키지 않게 해야 한다.  

### 4.5.5 복제와 내결함성

호스트가 다운되면 집계된 모든 이벤트를 잃게 된다.  
체크포인팅과 데드 레터 큐를 사용할 수 있다.  

가능한 해결책은 각 노드를 레디스와 같은 공유 인메모리 데이터베이스에 요청을 보내는 여러 상태 비저장 노드 클러스터로 구성된 독립적인 서비스로 전환하는 것이다.  

> 무슨 말인지 모르겠음


## 4.6 배치와 스트리밍 ETL

ETL은 하나 이상의 소스에서 데이터를 복사해 대상 시스템으로 옮기는 일반적인 절차다.  

- 배치 작업
  - 항상 정의된 주기에 실행
- 스트리밍
  - 이벤트가 발행될 때 실행

### 4.6.1 간단한 배치 ETL 파이프라인


### 4.6.2 메시징 용어

#### 메시징 시스템

#### 메시지 큐

#### 발행자/구독자

#### 메시지 브로커

#### 이벤트 스트리밍

#### 풀(pull)과 푸시(push)

일반적으로 풀이 푸시보다 낫고, 풀에서는 구독자가 메시지 소비 속도를 제어하므로 과부화되지 않는다.  

푸시는 시기적절한 업데이트를 가능하게 한다.  
푸시가 풀보다 나은 또 다른 예외는 오디오와 비디오 실시간 스트리밍과 같은 손실 허용 애플리케이션이다.  


### 4.6.3 카프카와 RabbitMQ

면접에서는 선입견이 있는 면접관의 신경을 거스릴 위험을 감수하기보다는 카프카와 RabbitMQ의 세부사항과 차이점에 관한 지식을 보여주고 트레이드오프를 논의하는 것이 더 안전하다.  

### 4.6.4 람다 아키텍처

람다 아키텍처는 배치와 스트리밍 파이프라인을 병렬로 실행해 빅데이터를 처리하는 데이터 처리 아키텍처다.  
같은 목적지를 업데이트하는 병렬 고속과 저속 파이프라인을 갖는 것을 의미한다.  

람다 아키텍처의 대안으로 카파(Kappa) 아키텍처가 있다.  


## 4.7 비정규화

더 빠른 읽기 연산을 위한 접근 방식은 JOIN 쿼리를 피하기 위해 스키마를 비정규화해 저장 공간을 속도와 맞바꾸는 것이다.  


## 4.8 캐싱

- 성능
- 가용성
- 확장성
  - 데이터 센터 간 요청이 느리고 지연 시간을 개선한다는 캐시의 주요 목적에 반하므로 캐시를 데이터 센터 간에 복제하지 않는다.
  - 백엔드 서비스는 백엔드와 데이터베이스의 용량에 맞춰 조정된 속도 제한 방식을 가져야 한다.

### 4.8.1 읽기 전략

#### 캐시 어사이드(지연 로드)

캐시 어사이드는 캐시가 데이터베이스 '옆에' 위치함을 의미하는 지연 로딩 방식이다.  

읽기 요청에서 애플리케이션은 먼저 캐시에 읽기 요청을 하고, 캐시 히트 시 데이터를 반환한다.  
캐시 미스 시 애플리케이션은 데이터베이스에 읽기 요청을 한 다음 데이터를 캐시에 쓴다.  
따라서 데이터는 처음 읽을 때만 로드되며, 이를 **지연 로드**라고 한다.  

여러 데이터베이스 요청의 결과를 단일 캐시 값으로 저장할 수 있다.  

오래된 데이터를 줄이려면 TTL을 설정하거나 쓰기 통과를 사용해 모든 쓰기가 캐시를 통과하게끔 할 수 있다.  
캐시 클러스터가 다운되면 모든 요청이 데이터베이스로 간다.  

#### 읽기 통과

**읽기 통과**나 **쓰기 통과** 또는 **지연 쓰기** 캐싱에서 애플리케이션은 캐시에 요청을 보내고, 필요하면 캐시가 데이터베이스에 요청을 보낼 수 있다.  

캐시 어사이드와 달리 읽기 통과 캐시는 여러 데이터베이스 요청을 단일 캐시 값으로 그룹화할 수 없다는 것이다.  


### 4.8.2 쓰기 전략

#### 쓰기 통과 방식

모든 쓰기 작업은 캐시를 거쳐 데이터베이스로 전달된다.  

- 장점
  - 일관성
  - 캐시가 오래된 상태가 되지 않음
- 단점
  - 모든 쓰기 작업이 캐시와 데이터베이스 양쪽에서 이뤄지므로 쓰기 속도가 느리다.
  - 신규 캐시 노드의 콜드 스타트 문제
  - 대부분의 데이터는 읽히지 않으므로 불필요한 비용 발생
  - 캐시 크기가 데이터베이스보다 작다면 캐시 제거 정책 필요

#### 지연 쓰기 / 후속 쓰기 방식

애플리케이션은 데이터를 캐시에 쓰지만 캐시는 즉시 데이터베이스에 쓰지 않는다.  
캐시는 주기적으로 갱신된 데이터를 데이터베이스에 플러시한다.  

- 장점
  - 쓰기 속도가 빠름
  - 데이터베이스 쓰기가 차단되지 않음
- 단점
  - 복잡도

#### 쓰기 우회 방식

애플리케이션은 데이터베이스에만 기록한다.  
캐시 미스가 발생할 때 캐시를 갱신한다.  


## 4.9 독립 서비스로서의 캐싱

- 각 호스트가 다른 데이터를 캐시할 수 있어 특정 요청에 캐시된 데이터가 있을 가능성이 낮다.
- 캐싱은 특히 핫 샤드를 유발하는 불균형한 요청 패턴이 있을 때 유용하다.
- 호스트에 캐시하면 서비스 배포 때마다 캐시가 삭제된다.
- 캐시를 서비스하는 대상과 독립적으로 확장할 수 있다.
- 많은 클라이언트가 동시에 캐싱 미스 같은 요청을 보내면 데이터베이스 서비스가 같은 쿼리를 여러 번 실행한다.


## 4.10 캐시할 수 있는 다양한 종류의 데이터와 캐싱 방법 예시

HTTP 응답이나 데이터베이스 쿼리를 캐시할 수 있다.  
캐시는 개인용 혹은 공용이거나 공유될 수 있다.  

- 개인 정보
- 주식 가격, 호텔 객실 같은 실시간 공개 정보
- 유료 저작권
- 변경될 수 있는 공개 정보는 캐시할 수 있지만, 원본 서버를 재검증해야 한다.

일반적으로 기업은 가능한 한 많은 처리와 저장을 클라이언트 기기로 옮기고 데이터 센터는 중요 데이터 백업과 사용자 간 통신에만 사용함으로써 하드웨어 비용을 절감할 수 있다.  

하지만 로컬스토리지 캐싱이 의도대로 작동한다고 가정하지 말고 항상 캐시 미스를 예상해 이러한 요청을 받을 준비를 해야 한다.  


## 4.11 캐시 무효화

캐시 무효화는 캐시 항목을 교체하거나 제거하는 과정이다.  

### 4.11.1 브라우저 캐시 무효화

브라우저 캐시에서는 보통 각 파일에 max-age를 설정한다.  

### 4.11.2 캐싱 서비스의 캐시 무효화

- 무작위 교체
- LRU
- FIFO
- LIFO


## 4.12 캐시 워밍

캐시 워밍은 해당 항목에 대한 첫 요청 전에 캐시를 항목으로 미리 채우는 것을 의미한다.  

- 캐시 워밍을 구현하는 데 따르는 추가적인 복잡성과 비용
- 캐시 워밍으로 인한 부하가 서비스에 과도하게 작용할 수 있다.
- 해당 데이터에 접근한 첫 사용자만 느린 경험을 한다.
- 캐시 만료 시간이 짧은 캐시 항목이 사용되기 전에 만료되어 캐시 워밍이 시간 낭비가 될 수 있다.

캐싱 없이 처리된 요청의 p99는 일반적으로 1초 미만이어야 한다.


## 4.13 추가 자료




