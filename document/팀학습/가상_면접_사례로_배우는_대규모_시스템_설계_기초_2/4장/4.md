# 4장 분산 메시지 큐

- 결합도 완화: 메시지 큐를 사용하면 컴포넌트 사이의 강한 결합이 사라진다.  
- 규모 확장성 개선
- 가용성 개선: 시스템의 특정 컴포넌트에 장애가 발생해도 다른 컴포넌트는 큐와 계속 상호작용을 이어갈 수 있다.  
- 성능 개선: 생산자는 응답을 기다리지 않고도 메시지를 보낼 수 있다.  

> 컴포넌트 간 결합도는 완화되지만, 카프카의 의존성이 높아짐  
> 카프카 장애 시 Failover를 고려해야 함  
> 규모 확장 시 카프카는 파티션을 고려해야 함  
> 컨슈머에서 장애 발생을 대비 한 DLT 고려해야 함  
> 메시지 성격(중요도)에 따라 일관성을 고려해야 함 (inbox, outbox pattern)  

### 메시지 큐 대 이벤트 스트리밍 플랫폼

아파치 카프카나 펄사는 메시지 큐가 아니라 이벤트 스트리밍 플랫폼이다.  

> Kafka와 RabbitMQ의 차이점은 무엇인가요?
> https://aws.amazon.com/ko/compare/the-difference-between-rabbitmq-and-kafka/
>
> Kafka를 메시지 큐로 사용 중  

## 1단계: 문제 이해 및 설계 범위 확정

생산자는 메시지를 큐에 보내고, 소비자는 큐에 메시지를 꺼낼 수 있으면 된다.  

- 메시지의 형태는 텍스트만 지원
- 메시지 크기는 수 KB 수준
- 하나의 메시지를 여러 소비자가 수신 가능해야 함
- 메시지가 생성된 순서로 소비되야 함
- 데이터의 지속성은 2주
- 지원해야 하는 생산자와 소비자는 많을 수록 좋음
- 메시지는 '최소 한 번'을 반드시 지원해야 함
- 높은 수준의 대역폭을 제공해야 함

### 기능 요구사항

### 비기능 요구사항

- 높은 대역폭과 낮은 전송 지연 가운데 하나를 설정으로 선택 가능해야 함
- 규모 확장성. 메시지 양이 급증해도 처리 가능해야 함
- 지속성 및 내구성. 데이터는 디스크에 지속적으로 보관되어야 하며 여러 노드에 복제되어야 함

### 전통적 메시지 큐와 다른 점

- 전통적인 큐는 메시지가 소비자에게 전달되기 충분한 기간 동안만 메모리에 보관
- 전통적인 메시지 큐는 생산된 순서와 소비되는 순서는 다를 수 있음


## 2단계: 개략적 설계안 제시 및 동의 구하기

### 메시지 모델

#### 일대일 모델

일대일 모델에서 큐에 전송된 메시지는 오직 한 소비자만 가져갈 수 있다.  
소비자가 메시지를 가져갔다는 사실을 큐에 알리면(acknowledge) 해당 메시지는 큐에서 삭제된다.  
이 모델은 데이터 보관을 지원하지 않는다.  

#### 발행-구독 모델

발행-구독 모델을 설명하려면 토픽이라는 새로운 개념을 도입해야 한다.  
메시지를 보내고 받을 때는 토픽에 보내고 받게 된다.  
이 모델에서 토픽에 전달된 메시지는 해당 토픽을 구독하는 모든 소비자에 전달된다.  


### 토픽, 파티션, 브로커

토픽에 보관되는 데이터의 양이 커져서 서버 한 대로 감당하기 힘들면 파티션(샤딩) 기법을 활용하여 해결할 수 있다.  
토픽을 여러 파티션으로 분할한 다음에 메시지를 모든 파티션에 균등하게 나눠 보낸다.  
파티션을 유지하는 서버는 보통 브로커라 부른다.  

각 토픽 파티션은 FIFO 큐처럼 동작한다.  
같은 파티션 안에서는 메시지 순서가 유지된다는 뜻이다.  
메시지 위치는 오프셋이라고 한다.  

메시지에는 사용자 ID 같은 키를 붙일 수 있는데, 같은 키를 가진 모든 메시지는 같은 파티션으로 보내진다.  

토픽을 구독하는 소비자는 하나 이상의 파티션에서 데이터를 가져오게 된다.  
이 소비자들을 해당 토픽의 소비자 그룹이라 부른다.  


### 소비자 그룹

하나의 소비자 그룹은 여러 토픽을 구독할 수 있고 오프셋을 별도로 관리한다.  
같은 그룹 내의 소비자는 메시지를 병렬로 소비할 수 있다.  

데이터를 병렬로 읽으면 대역폭 측면에서는 좋지만 같은 파티션 안에 있는 메시지를 순서대로 소비할 수는 없다.  

어떤 파티션의 메시지는 한 그룹 안에서는 오직 한 소비지만 읽을 수 있도록 제약사항을 추가하여 해결 가능하다.  
그룹 내 소비자의 수가 구독하는 토픽의 파티션 수보다 크면 어떤 소비자는 해당 토픽에서 데이터를 읽지 못하게 된다.  

이 제약사항을 도입한 후에 모든 소비자를 같은 소비자 그룹에 두면 같은 파티션의 메시지는 오직 한 소비자만 가져갈 수 있으므로 결국 일대일 모델에 수렴하게 된다.  
파티션은 가장 작은 저장 단위이므로 미리 충분한 파티션을 할당해 두면 파티션의 수를 동적으로 늘리는 일은 피할 수 있다.  


### 개략적 설계안

- 클라이언트
  - 생산자: 메시지를 특정 토픽으로 보낸다.  
  - 소비자 그룹: 토픽을 구독하고 메시지를 소비한다.
- 핵심 서비스 및 저장소
  - 브로커: 파티션들을 유지한다.
  - 저장소
    - 데이터 저장소: 메시지
    - 상태 저장소: 소비자 상태
    - 메타데이터 저장소: 토픽 설정, 속성
- 조정 서비스
  - 서비스 탐색: 어떤 브로커가 살아있는지 확인
  - 리더 선출
  - 아파치 주키퍼, etcd


## 3단계: 상세 설계

- 디스크 기반 자료 구조
- 데이터의 양이 막대한 경우에 메시지 복사 비용을 최소화하기 위한 자료 구조
- 일괄 처리를 우선하는 시스템


### 데이터 저장소

- 읽기와 쓰기가 빈번하게 일어난다.  
- 갱신/삭제 연산은 발생하지 않는다.  
- 순차적인 읽기/쓰기가 대부분이다.

#### 선택지1: 데이터베이스

- 관계형 데이터베이스: 토픽별로 테이블을 만든다.  
- NoSQL 데이터베이스: 토픽별로 컬렉션을 만든다. 

데이터 저장 요구사항을 맞출 수 있으나, 대규모 읽기/쓰기 연산 시 성능저하로 인한 시스템 병목이 될 수 있다.  

#### 선택지2: 쓰기 우선 로그(WAL)

WAL은 새로운 항목이 추가되기만 하는 일반 파일이다.  
MySQL의 복구 로그와 아파치 주키퍼도 WAL로 구현되어 있다.  

접근 패턴이 순차적일 때 디스크는 아주 좋은 성능을 보인다.  
회전식 디스크 기반 저장장치는 큰 용량을 저렴한 가격에 제공한다.  

로그 파일 줄 번호를 오프셋으로 사용한다.  
파일의 크기도 무한정 커질 수는 없으니, 세그먼트 단위로 나누는 것이 바람직하다.  

새 메시지는 활성 상태의 세그먼트 파일에만 추가된다.  
세그먼트의 크기가 일정 한계에 도달하면 새 활성 세그먼트 파일이 만들어지고, 기존 세그먼트 파일은 비활성 상태로 바뀐다.  
같은 파티션에 속한 세그먼트 파일은 Partition-{:partition_id} 폴더 아래에 저장된다.  

#### 디스크 성능 관련 유의 사항

회전식 디스크가 정말로 느려지는 것은 데이터 접근 패턴이 무작위일 때다.  
WAL도 OS가 제공하는 디스크 캐시 기능을 적극적으로 활용한다.  


### 메시지 자료 구조

#### 메시지 키

메시지 키는 파티션을 정할 때 사용된다.  
키가 주어진 경우 파티션은 hash(key) % numPartitions 공식에 따라 결정된다.  
파티션 번호는 메시지 큐 내부적으로 사용되는 개념이므로 클라이언트에 노출되어서는 안된다.  
키를 파티션에 대응시키는 알고리즘을 적절히 정의해 놓으면 파티션의 수가 달라져도 모든 파티션에 메시지가 균등히 분산되도록 할 수 있다.  

> 메시지 순차 처리를 위해 키를 사용하는 경우, 운영 중인 시스템의 파티션을 어떻게 늘릴 수 있을까?  
> 모듈러(%) 연산은 값이 달라지므로 불가능  
> 안정해시링?

#### 메시지 값

메시지 페이로드

#### 메시지의 기타 필드

- 토픽
- 파티션
- 오프셋
- 타임스탬프
- 크기
- CRC


### 일괄 처리

일괄 처리가 성능 개선에 중요한 이유
- 다수의 메시지를 한 번의 네트워크 요청으로 전송하므로 값비싼 네트워크 비용 제거
- 브로커가 여러 메시지를 한 번에 로그에 기록하면 큰 규모의 순차 쓰기 연산이 발생하고 연속된 공간을 점유하게 된다.  


### 생산자 측 작업 흐름

라우팅 계층은 '적절한' 브로커에 메시지를 보내는 역할을 담당한다.  
브로커를 여러 개로 복제하여 운용하는 경우, 리더 브로커가 담당한다.  

1. 생산자는 메시지를 라우팅 계층으로 보낸다.  
2. 라우팅 계층은 메타데이터 저장소에서 사본 분산 계획을 읽어 캐시에 보관하고, 메시지를 리더 사본에 보낸다.
3. 리더 사본이 메시지를 받은 다음에 다른 사본이 복제한다.  
4. '충분한'수의 사본이 동기화되면 리더는 데이터를 디스크에 기록하고, 생산자에게 회신을 보낸다.  

장애 감내 시스템 설계를 위해 리더와 사본이 존재한다.  

라우팅 계층으로 네트워크 오버헤드가 발생하여 전송 지연이 생긴다.  
일괄처리를 고려하지 않아 효율이 좋지 않다.  

라우팅 계층을 생산자 내부로 편입시키고, 버퍼를 도입한다.  
- 전송 지연이 줄어든다.  
- 생산자는 메시지를 어느 파티션에 보낼지 결정할 수 있다.  
- 전송할 메시지를 버퍼에 보관했다가 일관 전송하여 대역폭을 높일 수 있다.  

생산자는 메시지 큐의 용도를 감안하여 일괄 처리 메시지 양을 조정해야 한다.  


### 소비자 측 작업 흐름

소비자는 특정 파티션의 오프셋을 주고 해당 위치에서부터 이벤트를 묶어 가져온다.  

> lag은 최대한 0이 되야함  


### 푸시 vs 풀

#### 푸시 모델

장점
- 낮은 지연: 브로커는 메시지를 받는 즉시 소비자에게 보낸다.

단점
- 생산자의 메시지 생산 속도가 소비자의 메시지 소비 속도보다 빠를 경우, 소비자에게 큰 부하가 발생한다.  
- 소비자는 생산자의 데이터 전송 속도에 맞춰 컴퓨팅 자원을 준비해야 한다.  

#### 풀 모델

장점
- 메시지를 소비하는 속도는 소비자가 결정한다.  
- 메시지를 소비하는 속도가 느리면 소비자를 늘리거나, 모두 소비 될 때까지 기다려도 된다.
- 일괄 처리에 적합하다.

단점
- 브로커에 메시지가 없어도 소비자는 계속 데이터를 끌어가려 시도할 것이다. 롱 폴링 모드를 지원한다.   

풀 모델의 동작 흐름도
1. 소비자는 그룹 이름을 해싱하여 접속할 브로커 노드를 찾는다.  
2. 코디네이터는 소비자를 그룹에 참여시키고 파티션을 할당한다.
3. 소비자는 마지막 소비한 오프셋 이후 메시지를 가져온다.
4. 소비자는 메시지를 처리하고 새로운 오프셋을 브로커에 보낸다.

> 카프카 파티션 추가 시 auto.offset.reset 설정 확인이 필요함  
> 소비자의 auto.offset.reset 설정이 latest인 경우, 새로 추가된 파티션에는 offset이 없기 때문에 메시지 누락이 발생할 수 있음  
> 
> 18:00 파티션 추가  
> 18:01 A 메세지 발행 (offset 1)  
> 18:02 신규 파티션에 컨슈머 할당 (latest 옵션으로 offset1 (A메세지) 패스)  
> 
> 카프카 파티션 추가 전에는 earlist로 설정해야 함  

#### 소비자 재조정

소비자 재조정은 소비자가 어떤 파티션을 책임지는지 다시 정하는 프로세스다.  

코디네이터는 소비자 재조정을 위해 소비자들과 통신하는 브로커 노드다.  
코디네이터는 소비자의 heartbeat 메시지를 살피고 각 소비자의 파티션 내 오프셋 정보를 관리한다.  

- 코디네이터는 소비자 목록을 관리하고 목록이 변경되면 새 리더를 선출한다.
- 새 리더는 새 파티션 배치 계획을 만들고 코디네이터에게 전달한다. 코디네이터는 모든 소비자에게 계획을 알린다.  

코디네이터는 소비자의 heartbeat가 사라지는 현상을 통해 감지할 수 있다.  

#### 상태 저장소

- 소비자와 파티션의 배치 관계
- 마지막 메시지 오프셋

소비자 상태 정보 데이터 이용 패턴
- 읽기와 쓰기가 빈번하지만 양은 많지 않다.
- 데이터 갱신은 빈번하지만 삭제는 거의 없다.
- 읽기와 쓰기 연산은 무작위적 패턴이다.
- 데이터 일관성이 중요하다

주키퍼 같은 키-값 저장소를 사용하는 것이 적합하다.  

> 카프카는 4.0 버전부터 주키퍼가 제거되고, 크라프트(KRaft)’로 대체 되었다.  
> 
> Apache Kafka Zookeeper 제거 이유  
> https://velog.io/@joyfulbean/Apache-Kafka-Zookeeper-%EC%A0%9C%EA%B1%B0-%EC%9D%B4%EC%9C%A0

#### 메타데이터 저장소

메타데이터 저장소는 토픽 설정이나 속성 정보를 보관한다.  
메타데이터는 자주 변경되지 않으며 양도 적다.  
하지만 높은 일관성을 요구한다.  
주키퍼가 적합하다.  

#### 주키퍼

주키퍼는 계층적 키-값 저장소 기능을 제공하는 분산 시스템에 필수적인 서비스이다.  

- 메타데이터와 상태 저장소는 주키퍼로 구현한다.
- 브로커는 메시지 데이터 저장소만 유지하면 된다.
- 주키퍼가 브로커 클러스터의 리더 선출 과정을 돕는다.  

#### 복제

디스크에 영구적 장애로 데이터가 사라지는 문제를 해결하고 높은 가용성을 위해 복제(replication) 방법을 사용한다.  
사본들은 서로 다른 브로커 노드에 분산되어 있다.  

생산자는 리더에게만 메시지를 보낸다.  
사본은 리더에서 새 메시지를 지속적으로 가져와 동기화한다.  
메시지를 완전히 동기화한 사본의 개수가 지정된 임계값을 넘으면 리더는 생산자에게 응답(acknowledgement)을 보낸다.  

#### 사본 동기화

동기화된 사본(In-Sync Replicas, ISR)은 리더와 동기화된 사본을 일컫는 용어다.  
ISR은 성능과 영속성 사이의 타협점이다.  
어느 사본 하나라도 동기화를 신속하게 처리하지 못하게 되면 파티션 전부가 느려지거나 아예 못 쓰게 되는 일이 버어지고 말 것이다.  

#### ACK = all

생산자는 모든 ISR이 메시지를 수신한 뒤에 ACK 응답을 받는다.  

#### ACK = 1

생산자는 리더가 메시지를 저장하고 나면 바로 ACK 응답을 받는다.  
메시지 ACK을 보낸 직후 리더에 장애가 생기면 해당 메시지는 다른 사본에 반영되지 못하였으므로 복구할 길 없이 소실 된다.  

#### ACK = 0

생산자는 보낸 메시지에 대한 수신 확인ㅇ 메시지를 기다리지 않고 계속 메시지를 전송하며 어떤 재시도도 하지 않는다.  


가장 쉬운 구성은 소비자로 하여금 리더에서 메시지를 읽어가도록 하는 것이다.
- 리더 사본에서 메시지를 가져가는 것이 설계 및 운영이 단순하다.
- 같은 소비자 그룹 안에서는 오직 한 소비자만 읽어갈 수 있으므로 리더 사본에 대한 연결은 많지 않다.  
- 아주 인기 있는 토픽이 아니라면 리더 사본에 대한 연결의 수는 그렇게 많지 않다.  
- 아주 인기 있는 토픽의 경우에는 파티션 및 소비자 수를 늘려 규모를 확장하면 된다.

소비자의 위치가 리더 사본이 존재하는 데이터 센터와 다른 지역일 경우 성능이 나빠질 것이다.


### 규모 확장성

#### 생산자

생산자의 규모 확장성은 새로운 생산자를 추가하거나 삭제하면 된다.  

#### 소비자

소비자 그룹은 서로 독립적이므로 새 소비자 그룹을 추가/삭제하면 된다.  
같은 소비자 그룹 내의 소비자가 새로 추가/삭제되거나 장애가 발생하면 재조정 매커니즘이 맡아 처리한다.  

#### 브로커

- 사본이 많을수록 안전하지만, 응답 지연과 균형을 맞춰야 한다.
- 사본은 같은 노드에 두면 안 된다.
- 사본 수와 위치를 정할 때는 데이터 안전성, 자원 유지에 드는 비용 그리고 응답 지연 등을 고려해야 한다.

브로커 노드가 추가/삭제될 때 한시적으로 시스템에 설정된 사본 수보다 많은 사본을 허용하도록 한다.  

> Apache Kafka 클러스터 구성을 홀수로 하는 이유  
> https://judo0179.tistory.com/112  

#### 파티션

파티션의 수가 조정될 경우 생산자는 브로커와 통신할 때 통지 받으며, 소비자는 재조정을 시행한다.  
따라서 파티션 수의 조정은 생산자와 소비자의 안전성에는 영향을 끼치지 않는다.  

> 카프카는 파티션을 줄일 수 없음  


### 메시지 전달 방식

#### 최대 한 번 (at-most once)

생산자는 토픽에 비동기적으로 메시지를 보내고 응답을 기다리지 않는다. (ACK = 0)  
메시지 전달이 실패해도 다시 시도하지 않는다.  

소비자는 메시지를 읽고 처리하기 전에 오프셋부터 갱신한다.  
오프셋이 갱신된 직후에 소비자가 장애로 죽으면 메시지는 다시 소비될 수 없다.  

#### 최소 한 번 (at-least once)

같은 메시지가 한 번 이상 전달될 수는 있으나 메시지 소실은 발생하지 않는 전달 방식이다.  

생산자는 메시지를 동기/비동기적으로 보낼 수 있으며, ACK = 1 또는 ACK = all 구성을 이용한다.  
즉, 메시지가 브로커에게 전달되었음을 반드시 확인한다.  
메시지 전달이 실패하거나 타임아웃이 발생한 경우에는 계속 재시도할 것이다.  

> 구현체에 따라 다르겠지만 보통 ACK를 받을 때까지 무한 루프를 돌게 됨  
> 카프카에 장애가 발생할 경우 ACK를 못 받기 때문에 무한 루프에 빠질 수 있으므로, 최대 시도 횟수 등을 고려해야 함  
> 최대 시도 횟수까지 실패하면 DB에 남기는 등 failover를 고려해야 함  

소비자는 데이터를 성공적으로 처리한 뒤에만 오프셋을 갱신한다.  
메시지를 처리한 소비자가 미처 오프셋을 갱신하지 못하고 죽었다가 다시 시작하면 메시지는 중복 처리될 것이다.  

> 수동으로 ACK 날리도록 구현하는 방식은 위험함  
> 익셉션은 광범위하기 때문에 catch에 안잡혀서 ACK를 못 날리고, 같은 offset만 계속 재시도하는 현상을 봄  

이 방식은 메시지가 소실되는 일은 없지만 같은 메시지가 여러 번 전송될 수 있다.  

#### 정확히 한 번 (exactly once)

사용자 입장에서는 편리하지만, 시스템의 성능 및 구현 복잡도 측면에서는 큰 대가를 지불해야 한다.  

> 소비자는 어플리케이션에서 구현 해야 함  


### 고급 기능

#### 메시지 필터링

어떤 소비자 그룹은 특정한 세부/하위 유형의 메시지에만 관심이 있다.  

> 생산자는 소비자를 고려하면 안된다고 생각함  
> 생산자는 발생한 이벤트를 메시지로 발행할 뿐 소비자는 필요한 메시지만 받아가야 함  
> 물론 이벤트를 잘 정의하는 것이 첫 번째

필터링을 하기 위해 복호화나 역직렬화가 필요하다면 브로커 성능은 저하되고 말 것이다.  
따라서 브로커에 구현할 필터링 로직은 메시지의 내용을 추출해서는 안 된다.  
필터링에 사용될 데이터는 메시지의 메타데이터 영역에 두어 브로커로 하여금 효율적으로 읽어갈 수 있도록 해야 한다.  

#### 메시지의 지연 전송 및 예약 전송

브로커 내부의 임시 저장소에 넣어 두었다가 시간이 되면 토픽으로 옮긴다.  

> 배치를 활용하는게 좋지 않을까


## 4단계: 마무리

> 카프카는 기본적으로 메시지 소비 재시도가 3회로 되어 있음  
> 재시도에도 실패하면 DLT에 발행하고, DLT에 붙은 컨슈머가 처리하도록 아키텍처를 구성하면 되지 않을까  
> 영원히 처리가 안될 수 있으므로 최대 제한을 걸어 놓고, 제한이 된 메시지는 개발자가 수동으로 처리해야 함  


