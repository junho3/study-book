# 6장 광고 클릭 이벤트 집계

> OpenRTB 스펙  
> https://iabtechlab.com/standards/openrtb/  
> https://www.iab.com/wp-content/uploads/2016/03/OpenRTB-API-Specification-Version-2-5-FINAL.pdf  
> 
> 비딩 금액  
> 사이트 성격  
> 지면 크기와 위치  
> 디바이스, OS  
> 지역정보, 사용자정보

## 1단계: 문제 이해 및 설계 범위 확정

- ad_id, (area_id or inventory_id), click_time-stamp, user_id, ip, country 수집
- 매일 10억 개의 광고 클릭이 발생하고, 광고는 200만 회 게재된다.
- 광고 클릭 이벤트 수는 매년 30%씩 증가한다고 가정한다.
- 질의 조건
  - 특정 광고에 대한 지난 M분간 클릭 이벤트 수
  - 지난 1분간 가장 많이 클릭된 광고 100개. 질의 기간과 광고 수는 변경 가능해야 함
  - ip, user_id, country 등의 속성을 기준으로 질의 결과를 필터링해야 함 
- 엣지 케이스
  - 예상보다 늦게 도착하는 이벤트
  - 중복된 이벤트
  - 시스템이 다운될 수 있으므로 시스템 복구를 고려해야 함
- RTB는 응답이 1초 이내여야 함
- 광고 클릭 집계는 몇 분 정도의 지연은 허용 가능

### 기능 요구사항

### 비기능 요구사항

- 집계 결과 정확성이 높아야 함
- 지연되거나 중복된 이벤트(어뷰징)를 처리할 수 있어야 함
- 부분적인 장애는 감내할 수 있어야 함
- 전체 처리 시간은 최대 수 분을 넘지 않아야 함

> 10분마다 데이터 집계를 했었음

### 개략적 추정

- DAU 10억 명
- 하루에 10억 건의 광고 클릭 이벤트 발생
- 광고 클릭 QPS = 10,000
- 최대 광고 클릭 QPS는 50,000 QPS로 가정
- 광고 클릭 이벤트 하나당 0.1KB의 저장 용량 필요. 
  - 일간 저장소 요구량은 0.1KB X 10억 = 200GB
  - 월간 저장소 요구량은 3TB

> 로그 처리 서버는 집계한 데이터를 압축해서 N일동안 보관 후 삭제  
> 로우 데이터는 S3에 적재 후 AWS Athena로 조회  


## 2단계: 개략적 설계안 제시 및 동의 구하기

### 질의 API 설계

#### API 1: 지난 M분간 각 ad_id에 발생한 클릭 수 집계

`GET: /v1/ads/{:ad_id}/aggregated_count?from=xxxx&to=xxxx&filter`

#### API 2: 지난 M분간 가장 많은 클릭이 발생한 상위 N개 ad_id 목록

`GET: /v1/ads/popular_ads?count=xxx&window=xxx&filter=xxxx`

### 데이터 모델

#### 원시 데이터

로그 파일에 포함된 원시 데이터

`ad001, 2021-01-01 00:00:01, user 1, 207.148.22.22, USA`

#### 집계 결과 데이터

| time             | ad_id | area_id | impression | click | price |
|------------------|-------|---------|------------|-------|-------|
| 2024.02.25 14:30 | ad001 | area001 | 100        | 5     | 100   |

> 책에서는 filter_id 컬럼을 갖고 있는데, 목적에 맞는 테이블을 구성하는게 더 낫다고 생각 함  
> 광고 보고서 페이지에서 다양한 필터 기능을 제공하지만, 실제로 사용하는 필터는 거의 고정되어 있음  

#### 비교

원시 데이터와 집계 결과 데이터 모두 저장하는 것을 추천한다.  

- 문제가 발생하면 디버깅에 활용할 수 있도록 원시 데이터도 보관하는 것이 좋다.  
- 원시 데이터는 양이 엄청나므로 직접 질의하는 것은 비효율적이다.  
- 원시 데이터는 백업 데이터로 활용되다. 오래된 원시 데이터는 cold storage로 옮기면 비용을 절감할 수 있다.   
- 집계 결과 데이터는 활성 데이터 구실을 한다.

> 원시 데이터는 json 형식의 파일로 관리 (AWS S3)  
> 원시 데이터는 사용자/광고/영역 지표 분석에 활용 됨  
> 
> 집계 데이터는 RDB에 저장하고, 목적에 따라 테이블이 다양함  
> 일별/월별 집계 테이블, 광고별/영역별 집계 테이블 등..

### 올바른 데이터베이스의 선택

올바른 데이터베이스를 선택하려면 다음과 같은 사항을 평가해 보아야 한다.  

- 데이터는 어떤 모습인가?
  - 관계형 데이터인가?
  - 문서 데이터인가?
  - 이진 대형 객체 (BLOB)인가?
- 작업 흐름이 읽기 중심인가 쓰기 중심인가? 아니면 둘 다인가?
- 트랜잭션을 지원해야 하는가?
- 질의 과정에서 SUM이나 COUNT 같은 온라인 분석 처리(OLAP) 함수를 많이 사용해야 하는가?

원시 데이터는 일상적인 작업에는 질의할 필요가 없지만, 데이터 연구 목적으로 유용하다.  
설계 범위 확정 단계에서 평균 쓰기 10,000 QPS이고, 최대 50,000QPS 이므로 쓰기 중심 시스템이다.  

ORC, Parquet, AVRO 같은 컬럼형 데이터 형식 가운데 하나를 사용하여 아마존 S3에 데이터를 저장하는 방법도 있다.  
이 구성은 많은 사람들에게 낯설 것이므로, 본 설계안에서는 카산드라를 활용한다.  

집계 데이터는 본질적으로 시계열 데이터이며 이 데이터를 처리하는 워크플로는 읽기 연산과 쓰기 연산을 둘 다 많이 사용한다.  
각 광고에 대해 매 분마다 데이터베이스에 질의를 던져 고객에게 최신 집계 결과를 제시해야 하기 때문이다.  
집계 서비스가 데이터를 매 분 집계하고 그 결과를 기록하므로 쓰기 작업도 아주 빈번하게 이루어진다.  
원시 데이터와 집계 결과 데이터를 저장하는 데는 같은 유형의 데이터베이스를 활용하는 것이 가능하다.  

### 개략적 설계안

실시간으로 빅데이터를 처리할 때 데이터는 보통 무제한으로 시스템에 흘러 들어왔다가 흘러나간다.  
입력은 원시 데이터이고, 출력은 집계 결과다.  

#### 비동기 처리

데이터를 동기식으로 처리하는 방식은 생산자와 소비자 용량이 항상 같을 수는 없으므로 좋지 않다.  
트래픽이 갑자기 증가하여 발생하는 이벤트 수가 소비자의 처리 용량을 훨씬 넘어서는 경우, 소비자는 메모리 부족 오류 등의 예기치 않은 문제를 겪게 될 수 있다.  

이 문제를 해결하는 방안은 카프카 같은 메시지 큐를 도입하여 생산자와 소비자의 결합을 끊는 것이다.  

집계 결과를 데이터베이스에 바로 기록하지 않는 이유는 정확하게 한 번(exactly once) 데이터를 처리하기 위해 카프카 같은 시스템을 두 번째 메시지 큐로 도입해야 하기 때문이다.  

### 집계 서비스

광고 클릭 이벤트를 집계하는 좋은 방안은 맵리듀스 프레임워크를 사용하는 것이다.  
DAG 모델의 핵심은 시스템을 맵/집계/리듀스 노드 등의 작은 컴퓨팅 단위로 세분화하는 것이다.  
각 노드는 한 가지 작업만 처리하며, 처리 결과를 다음 노드에 인계한다.  

#### 맵 노드

맵 노드는 데이터 출처에서 읽은 데이터를 필터링하고 변환하는 역할을 담당한다.  
입력 데이터를 정리하거나 정규화해야 하는 경우에는 맵 노드가 필요하다.  

#### 집계 노드

집계 노드는 ad_id 별 광고 클릭 이벤트 수를 매 분 메모리에서 집계한다.  

##### 리듀스 노드

리듀스 노드는 모든 '집계' 노드가 산출한 결과를 최종 결과로 축약한다.  

DAG는 맵리듀스 패러다임을 표현하기 위한 모델이다.  
빅데이터를 입력으로 받아 병렬 분산 컴퓨팅 자원을 활용하여 빅데이터를 작은 크기 데이터로 변환할 수 있도록 설계된 모델이다.  
이 모델의 중간 데이터는 메모리에 저장될 수 있으며, 노드 간 통신은 TCP로 처리할 수도 있고 공유 메모리로 처리할 수도 있다.  

##### 주요 사용 사례

###### 사례 1: 클릭 이벤트 수 집계

###### 사례 2: 가장 많이 클릭된 상위 N개 광고 반환

###### 사례 3: 데이터 필터링

> RDB에서 필터링할 컬럼에 유니크 키를 설정하는 것으로 이해 함  




