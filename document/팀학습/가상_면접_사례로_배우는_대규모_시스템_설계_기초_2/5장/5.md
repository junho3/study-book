# 5장 지표 모니터링 및 경보 시스템

## 1단계: 문제 이해 및 설계 범위 확정

지표 모니터링 및 경보 시스템의 의미는 회사마다 다를 수 있으므로, 면접관과 상의하여 정확한 요구사항을 알아내는 것이 중요하다.  

### 개략적 요구사항 및 가정

- 회사 내부 시스템 (Sass 아님)
- CPU 부하, 메모리 사용률, 디스크 사용량, TPS, 메시지 큐의 메시지 수 ...
- DAU 1억 명, 1000개의 서버 풀, 풀마다 100개의 서버 하드웨어
- 데이터는 1년간 보관
- 신규 데이터는 7일동안 보관 > 1분 단위 데이터로 만들어 30일동안 보관 > 1시간 단위 데이터로 만들어서 1년동안 보관
- 이메일, 전화, 페이저듀티, 웹훅 등을 채널로 지원해야 함
- 에러 로그나 액세스 로그는 수집하지 않아도 됨
- 분산 시스템 추적을 지원하지 않아도 됨

> 페이저 듀티  
> PagerDuty는 모든 소프트웨어에 실시간 서비스를 제공하여 시스템 오류 신호를 인지하고 해석하여 이를 적절한 팀원들에게 실시간 조치를 취하도록 알려주며 소프트웨어와 인간의 반응 정보를 머신러닝을 통해 자동화 프로세스를 지속적으로 플랫폼 내에 저장하여 향후 일어날 사고에 대해 사전 대처를 할 수 있도록 도와주는 서비스를 제공하고 있습니다.  
> https://overseasmarket.tistory.com/211  

### 비기능 요구사항

- 규모 확장성
- 낮은 응답 지연
- 안정성: 중요 경보를 놓치지 않아야 함
- 유연성: 미래의 신기술을 쉽게 통합할 수 있도록 유연하게 변경 가능한 파이프라인을 이용해 구축해야 함


## 2단계: 개략적 설계안 제시 및 동의 구하기

### 기본적 사항

- 데이터 수집
- 데이터 전송
- 데이터 저장소
- 경보
- 시각화

### 데이터 모델

지표 데이터는 통상 시계열 데이터 형태로 기록한다.  

CPU.load host=webserver01,region=us-west 1613707265 50

- CPU.load: 지표 이름  
- host=webserver01,region=us-west: 태그/레이블 집합  
- 1613707265 50: 지표 값 및 그 타임스탬프의 배열

시스템에 대한 쓰기 부하는 막대하다.  
읽기 부하는 일시적으로 치솟았다 사라지는 편이다.  

> SRE팀으로부터 읽기 부하 때문에 브라우저에서 grafana를 계속 켜두지 말아달라는 요청이 있었음  

### 데이터 저장소 시스템

지표 모니터링 및 경보시스템을 위한 저장소 시스템을 직접 설계하거나, MySQL 같은 범용 저장소 시스템을 사용하는 선택지를 추천하지 않는다.  
범용 데이터베이스는 이 설계안이 감당하려는 부하 규모에 맞추려면 전문가 수준의 튜닝이 필요하다.  

관계형 데이터베이스는 시계열 데이터를 대상으로 수행하는 연산에 최적화되어 있지 않다.  
태그/레이블 질의를 지원하려면 태그마다 인덱스를 지정해야 하는 문제가 있다.  
많은 양의 쓰기 연산이 지속적으로 발생하는 환경에서 성능이 좋지 않다.  

NoSQL로 시계열 데이터를 효과적으로 저장하고 질의하기 위해서는 확장이 용이한 스키마를 설계해야 하는데, NoSQL에 대한 이해도가 높아야 한다.  

- OpenTSDB: Hadoop과 HBase 기반
- MetrixcsDB: 트위터
- Timestream: AWS
- InfluxDB
- Prometheus

> Promethus 사용 중  

좋은 시계열 데이터베이스는 막대한 양의 시계열 데이터를 레이블 기준으로 집계하고 분석하는 기능을 제공한다.  
레이블 기반의 신속한 데이터 질의를 지원하기 위해 레이블별로 인덱스를 구축한다.  
레이블을 이용할 때 데이터베이스 과부하를 피하는 지침도 제공한다.  

### 개략적 설계안

- 지표 출처: 지표 데이터가 만들어지는 애플리케이션, DB, 메시지 큐 등..
- 지표 수집기: Prometheus
- 시계열 데이터베이스
- 질의 서비스: Grafana
- 경보 시스템: Slack, Opsgenie
- 시각화 시스템: Grafana


## 3단계: 상세 설계

### 지표 수집

지표 수집은 때로 데이터가 소실되어도 심각한 문제는 아니다.  
클라이언트는 성공적으로 데이터가 전송되었는지 신경 쓰지 않아도 된다.  

#### 풀 모델

지표 수집기 서버가 모든 서비스 앤드포인트를 관리하고, 주기적으로 지표 데이터를 가져온다.  
서버가 수시로 추가/삭제되는 대규모 운영 환경에는 적용하기 어렵다.  
etcd, 아파치 주키퍼 같은 서비스 탐색 기술을 활용하면 이 문제를 해결할 수 있다.  

지표 수집기 서버가 여러 대일 때 같은 출처에서 데이터를 중복해서 가져올 가능성이 있다.  
안정 해시 링을 사용해서 해당 구간에 속한 서버로부터 생산되는 지표 수집을 담당하는 수집기 서버를 지정하는 것이다.  

#### 푸시 모델

웹 서버나 데이터베이스가 직접 지표를 수집기에 전송하는 모델이다.  
모니터링 대상 서버에 통상 수집 에이전트 소프트웨어를 설치한다.  

데이터 집계는 수집기에 보내는 데이터의 양을 줄이는 효과적인 방법이다.  
만일 에이전트가 위치한 서버가 오토 스케일링으로 동적으로 추가되거나 삭제될 때 데이터가 소실될 수도 있다.  
지표 수집기 클러스터도 오트 스케일링 설정을 추가하고 로드벨렌서를 두는 것이 좋다.  

#### 풀모델 vs 푸시 모델 장단점 비교

- 풀 모델
  - Prometheus
  - 어플리케이션 서버에 /metrics 엔드포인트를 두도록 강제하므로 디버깅이 쉽다.
  - 어플리케이션 서버가 풀 요청에 응답하지 않으면 장애가 발생한 것으로 진단할 수 있다.
  - 모든 /metrics 엔드포인트를 접근 가능해야하므로 네트워크 설계에 주의해야한다.
  - 일반적으로 TCP를 사용한다.
  - 지표 데이터를 가져올 목록이 정의된 상태이므로 수집 데이터를 믿을 수 있다.
- 푸시 모델
  - AWS CloudWatch, Graphite
  - 지표 수집기가 지표를 받지 못 하면 네트워크 장애인지, 서버 장애인지 알 수가 없다.  
  - 생명 주기가 짧은 프로세스가 종료되기 전에 지표를 보낼 수 있다.
  - 보통 UDP를 사용하므로 지표 전송 지연이 더 낮다.
  - 아무나 지표 수집기에 데이터를 보낼 수 있다는 문제가 있다.  

### 지표 전송 파이프라인의 규모 확장

시계열 데이터베이스에 장애가 생기면 데이터 손실이 발생할 가능성이 있다.  
큐를 두면 그런 문제를 해소할 수 있다.  

지표 수집기는 지표 데이터를 카프카와 같은 큐 시스템에 전송한다.  
아파치 스톰이나 플링크, 스파크 같은 스트림 처리 서비스가 해당 데이터를 받아 시계열 데이터베이스에 저장한다.  

- 데이터 수집 컴포넌트와 처리 컴포넌트 사이의 결합도를 낮춘다.
- 데이터베이스에 장애가 생겨도 데이터는 소실되지 않는다.

> 수집 컴포넌트와 처리 컴포넌트 사이의 결합도를 낮추는 것은 동의  
> 카프카가 장애나면??  

#### 카프카를 통한 규모 확장

- 태그/레이블에 따라 지표데이터를 더욱 세분화한 파티션으로 나눈다.  
- 중요 지표가 먼저 처리될 수 있도록 지표를 분류하고 우선순위를 지정한다.  

> 단일 토픽에 지표별로 파티션을 분류한다는 의미인건지?  
> 지표는 언제든지 추가될 수 있을탠데, 그 때마다 파티션을 늘린다는건지?  
> 카프카는 파티션별로 메세지 순서가 보장되는데, 중요 지표가 먼저 처리될 수 있도록 우선순위를 지정한다는게 어떤 의미인지?  

#### 카프카의 대안

페이스북의 메모리 기반 시계열 데이터베이스 시스템 고릴라는 일부에 네트워크 장애가 발생해도 높은 ㅜ준의 쓰기 연산 가용성을 유지한다.  

> 페이스북의 고릴라  
> https://jessicagreben.medium.com/four-minute-paper-facebooks-time-series-database-gorilla-800697717d72

### 데이터 집계 지점

#### 수집 에이전트가 집계하는 방안

클라이언트에 설치된 수집 에이전트는 복잡한 집계 로직을 지원하기 어렵다.  

#### 데이터 수집 파이프라인에서 집계하는 방안

플링크 같은 스트림 프로세싱 엔진이 필요하다.  
데이터베이스에는 계산 결과만 기록하므로, 실제로 기록되는 양은 엄청나게 줄어들 것이다.  
늦게 도착한 지표 데이터 처리가 어렵고, 원본 데이터를 보관하지 않기 때문에 정밀도나 유연성 측면에서 손해를 본다.  

#### 질의 시에 집계하는 방안

데이터 손실 문제는 없으나 질의를 처리하는 순간 집계 결과를 계산해야 하므로 속도는 느리다.  

### 질의 서비스

질의 처리 전담 서비스를 두면 클라이언트와 시계열 데이터베이스의 결합도를 낮출 수 있다.  
그렇게 되면 시계열 데이터베이스를 자유롭게 다른 제품으로 교체할 수 도 있다.  

#### 캐시 계층

#### 질의 서비스를 두면 곤란한 경우

캐시를 도입할 필요가 없는 시계열 데이터베이스가 있다는 것도 고려할 사항이다.  

#### 시계열 데이터베이스 질의어

시계열 데이터베이스 분석에 최적화된 플럭스라는 언어로 작성하면 질의문이 간단해진다.  

### 저장소 계층

#### 시계열 데이터베이스는 신중하게 선택할 것

질의의 85%는 지난 26시간 내에 수집된 데이터를 대상으로 한다.  
이 사실을 잘 활용하는 시계열 데이터베이스를 고르면 성능 측면에서 큰 이득을 볼 수 있다.  

> InfluxDB는 2가지 핵심 기능을 제공하고 있는데, 그것은 바로 일정 주기마다 데이터를 처리하여 새롭게 저장하는 기능과 일정 주기마다 데이터를 자동으로 삭제하는 기능이다.  
> https://mangkyu.tistory.com/190  

#### 저장 용량 최적화

##### 데이터 인코딩 및 압축

타임스탬프 하나를 온전히 표현하는 데는 32비트가 필요하지만, 10을 표현하는데는 4비트면 충분하다.  
따라서 데이터를 완전한 형태로 저장하는 대신 기준값과의 차이를 1610087371, 10(1610087381), 10(1610087391), 9(1610087400), 11(1610087411)과 같이 저장한다.  

##### 다운샘플링

데이터의 해상도를 낮춰 저장소 요구량을 줄이는 기법이다.  
- 7일 이내 데이터는 샘플링을 적용하지 않는다.  
- 30일 이내 데이터는 1분 해상도로 낮춰 보관한다.
- 1년 이내 데이터는 1시간 해상도로 낮춰 보관한다.  

> 첫 회사 광고 보고서 구현할 때도 다운샘플링 기법을 사용했음  
> 로우 데이터는 시간 단위로 집계했는데, 데이터가 많아지면서 일주일 또는 월별 보고서는 로딩 속도가 저하되는 문제가 발생함  
> D+1 데이터는 시간 단위로 쌓여있는 로우 데이터를 활용하고, D+2부터 일별 집계 데이터를 합산하도록 구현하여 속도 이슈 해결    

##### 냉동 저장소

잘 사용되지 않는 비활성 상태 데이터를 보관하는 곳이다.  
비용이 저렴하다.  

### 경보 시스템

규칙은 YAML로 관리하고, 캐시 서버에 보관한다.  
경보 시스템은 주기적으로 질의 서비스를 호출하고, 임계값을 위반하면 경보 이벤트를 생성한다.  
컨슈머가 이벤트를 읽어 이메일, 메시지 등 다양한 채널로 알림을 전송한다.  

#### 경보 시스템 - 만들 것인가 구매할 것인가

시장에는 경보 시스템이 많다.  
따라서 실무에서 경보 시스템을 밑바닥부터 구현하겠다는 아이디어는 수용되기 어렵다.  
따라서 면접에서는 본인 선택을 정당화할 수 있도록 준비해야 한다.  

> Datadog은 기능이 훌륭하지만, 사용료가 비쌈  
> 회사가 돈이 많다면 사용하는 듯   
> 
> Prometheus는 DB 지표를 다양하게 가져올 수 없어서 Datadog을 사용하는 듯  
> 
> 금융권 회사는 보안이슈로 Saas 사용이 어려울 수도 있을 듯  

### 시각화 시스템

시각화 시스템은 데이터 계층 위에 만들어진다.  
품질 좋은 시각화 시스템은 구현하기 어렵다.  
따라서 사용품을 구입해서 쓰자고 주장하는 것이 바람직하다.  


## 4단계: 마무리



