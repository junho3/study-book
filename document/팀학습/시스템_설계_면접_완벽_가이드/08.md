# 08 속도 제한 서비스 설계

속도 제한(Rate limiting)은 소비자가 API 엔드포인트에 요청할 수 있는 속도를 정의한다.  
속도 제한은 특히 봇과 같은 클라이언트의 의도하지 않거나 악의적인 과도한 사용을 방지한다.  

이러한 의도하지 않은 과도한 사용은 '시끄러운 이웃' 문제를 일으킨다.  

- DDos
- 무차별 대입 공격(Brute force attack)
- 웹 스크래핑


## 8.1 속도 제한 서비스의 대안과 그것이 실현 불가능한 이유

트래픽 급증이 감지될 때 새 호스트를 추가하는 과정이 너무 느릴 수 있다.  

로드 밸런서는 각 호스트로 보내는 요청 수를 제한할 수 있다.  

속도 제한기는 보통 429 Too Many Requests를 반환할 수 있으나, 특정 요청이 악의적이라고 확신한다면 다음 옵션 중 하나를 선택할 수 있다.  

- 요청을 버리고 응답을 반환하지 않아 공격자가 서비스에 장애가 발생했다고 생각하게 한다.
- 사용자를 섀도우 밴해서 200을 반환하되, 빈 응답이나 오해의 소지가 있는 응답을 보낸다.

사용자의 요청을 같은 호스트로 라우팅하는 고정 세션을 위해서는 7계층 로드 밸런서가 필요한데, 이는 비용과 복잡성을 증가시킨다.  


## 8.2 속도 제한을 하지 말아야 할 때

속도 제한이 모든 종류의 클라이언트 과다 사용에 적절한 해결책은 아니다.  


## 8.3 기능적 요구사항

- 속도 제한은 각 서비스에서 독립적이다.
- 사용자는 엔드포인트당 하나씩 여러 개의 속도 제한을 설정할 수 있다.
- 사용자는 어떤 사용자가 속도 제한이 됐는지, 언제 시작되고 끝났는지 볼 수 있어야 한다.
- 모든 요청을 로깅해야 하는지 면접관과 논의할 수 있다.
- 후속 조치와 분석을 위해서는 속도가 제한된 요청자를 로깅해야 한다.


## 8.4 비기능적 요구사항

속도 제한은 서비스 가용성에 필수적이지 않으므로 고가용성과 내결함성을 트레이드오프할 수 있다.  

### 8.4.1 확장성

서비스는 일일 수십억 건의 요청으로 확장할 수 있어야 한다.  

10초 이내에 100만에서 1,000만 명 이상의 사용자가 있을지에 대해 면접관과 논의할 수 있다.  
전체 저장 공간 요구사항은 `100(속데 제한이 필요한 서비스 수) * 64(타임스탬프 용량) * 101 * 1,000만(사용자) = 808GB`이다. 


### 8.4.2 성능

속도 제한기 요청의 응답 시간이 사용자 요청의 응답 시간에 추가된다.  
따라서 서비스는 매우 낮은 지연 시간이 필요하며, P99가 100ms여야 할 것이다.  


### 8.4.3 복잡성

서비스는 조직의 다른 많은 서비스가 사용하는 공유 서비스가 될 것이다.  
설계는 버그와 중단의 위험을 최소화하고, 문제 해결을 돕고, 속도 제한기로써 단일 기능에 집중할 수 있게 하며, 비용을 최소화하려면 단순해야 한다.


### 8.4.4 보안과 프라이버시

다른 서비스의 요청을 위조해 속도를 제한하는 등의 방식으로 속도 제한기를 공격하려 할 수 있다.  


### 8.4.5 가용성과 내결함성

고가용성이나 내결함성은 필요하지 않을 수 있다.  


### 8.4.6 정확성

사용자 경험 저하를 방지하려면 과도한 클라이언트를 잘못 식별해 속도를 제한해서는 안 된다.  


### 8.4.7 일관성

몇 초간의 불일치는 허용될 수 있다.  
로그 분석을 수행할 때도 최종 일관성이 허용된다.  
강한 일관성 대신 최종 일고나성을 사용하면 더 단순하고 저렴한 설계가 가능하다.  


## 8.5 사용자와 스토리가 필요한 서비스 구성 요소

속도 제한 요청에는 사용자 ID와 사용자 서비스 ID가 필수로 포함된다.  
속도 제한이 각 사용자 서비스에서 독립적이므로 ID 형식은 각 사용자 서비스에 특화될 수 있다.  

속도 제한기는 사용자 ID, 사용자 ID 데이터를 60초 동안 저장해야 한다.  
이는 사용자의 요청 속도가 속도 제한보다 높은지 판단하기 위해 이 데이터를 사용해야 하기 때문이다.  

로그에는 일관성과 지연 시간이 요구되지 않으므로 HDFS와 같은 최종 일관성 저장소에 로그를 저장할 수 있다.  


## 8.6 고수준 아키텍처

전체 지연 시간을 줄이려면 각 단계 스레드를 분기하거나 공통 스레드 풀의 스레드를 사용해 단계를 병렬로 수행할 수 있다.  

백엔드는 읽기/SELECT 쿼리만 팔로워 노드에 수행해야 한다.  

규칙이 자주 변경되지 않을 것으로 예상되므로 규칙 서비스에 레디스 캐시를 추가해 읽기 성능을 더욱 향상시킬 수 있다.  

> API 게이트웨이에서 Rate limiting을 수행해야하는게 아닌지?  
> 백엔드 뒷단에 위치할 경우 결국 모든 트래픽을 백엔드가 받아야된다는 의미인데, 백엔드 뒷단에서 수행하도록 설계한 이유를 이해하지 못 함


## 8.7 상태 저장 접근 방식/샤딩

상태 저장 접근 방식은 7계층 로드 밸런서가 필요하다.  
7계층 로드 밸런서 사용에 대해 각 호스트가 비용이 많이 드는 요청을 거부하고 자체 속도 제한을 수행할 수 있게 고정 세션을 위해서가 아니라 분산 속도 제한 솔루션에서 사용하는 것을 설명하고 있음에 주목한다.  

이러한 접근 방식에서 즉시 제기되는 질문은 내결함성, 즉 호스트가 다운됐을 때 데이터 손실을 방지해야 하는지 여부다.  
특정 사용자의 데이터가 포함된 호스트가 다운되면 다른 호스트를 해당 사용자에게 할당하고 영향을 받은 사용자의 요청 속도 카운트를 0부터 다시 시작할 수 있다.  

속도 제한 서비스를 개발할 때 호스트 설정 프로세스가 몇 분을 초과하지 않게 해야 한다.  
핫 샤드를 모니터링하고 주기적으로 호스트 간 트래픽을 재조정해야 한다.  

이 접근 방식의 트레이드오프는 DDos 공격 복원력이 떨어진다는 것이다.  
초당 수백 건의 요청을 하면, 할당된 호스트가 이를 처리할 수 없고 이 호스트에 핟랑된 모든 사용자의 속도를 제한할 수 없게 된다.  
로드 밸런서는 이 IP 주소의 요청을 드롭해야 한다.  


## 8.8 모든 호스트에 모든 카운트 저장

속도 제한기를 해당 서비스의 성능 저하 가능성에 노출시키는 외부 레디스 서비스 의존성을 피할 수 있을까?

### 8.8.1 고수준 아키텍처

속도 제한이 정확하게 계산되려면 호스트의 속도 제한을 동기화해야 한다.  
배치 업데이트가 너무 드물고 설정된 요청 속도보다 훨씬 높은 요청 속도에서 사용자의 속도가 제한되므로 배치 업데이트 대신 스트리밍을 사용한다.  

이 설계는 일관성과 정확성을 낮은 지연 시간 및 높은 성능과 맞바꾸는 방식이다.  

- 호스트는 메모리의 데이터로 속도 제한 결정을 내릴 수 있다.  
- 데이터 동기화는 독립적인 프로세스에서 수행할 수 있다.  


### 8.8.2 카운트 동기화

일관성과 정확성을 양보하는 대신 더 높은 성능, 낮은 리소스 소비, 낮은 복잡도를 얻기 위해 푸시 방식을 선택할 수 있다.  
호스트가 TCP 대신 UDP를 사용해 비동기적으로 타임스탬프를 공유하게 결정할 수 있다.  


#### 전체 대 전체

전체 대 전체(All-to-all)는 그룹 내의 모든 노드가 다른 모든 노드에 메시지를 전송하는 것을 의미한다.  
완전 메시(full mesh) 토폴로지를 필요로 한다.  
노드 수에 따라 제곱으로 확장되므로 확장 가능하지 않다.  

128 * 128 * 64MB = 1TB 이상 필요


#### 가십 프로토콜

가십 프로토콜은 노드가 무작위로 다른 노드를 선택해 메시지를 보낸다.  

이 접근 방식은 일관성과 정확성을 낮춰 더 높은 성능과 더 낮은 리소스 소비를 얻을 수 있으나 더 복잡하기도 하다.  

모든 노드가 다른 노드의 IP 주소를 알아야 한다는 의미다.  


#### 외부 저장소와 조정 서비스

호스트는 주키퍼와 같은 클러스터의 구성 서비스에 의해 선택된다.  
각 호스트는 리더 호스트의 IP 주소만 알면되고, 리더 호스트는 주기적으로 호스트 목록을 업데이트해야 한다.  


#### 무작위 리더 선출

리더를 선출하는 간단한 알고리즘을 사용해 복잡성을 낮추는 대신 더 높은 리소스 소비를 택할 수 있다.  


## 8.9 속도 제한 알고리즘

특정 시스템 설계 면접 질문에는 대부분의 지원자가 경험하지 못한 전문 지식과 전문성이 포함될 수 있다는 점을 밝혀둔다.  
면접관은 우리가 속도 제한 알고리즘에 익숙할 것을 기대하지 않을 수 있다.  
이는 지원자의 의사소통 기술과 학습 능력을 평가할 기회다.  


### 8.9.1 토큰 버킷

요청이 도착할 때마다 버킷에서 토큰을 하나 제거한다.  
토큰이 없으면 요청이 거부되거나 속도가 제한된다.  
버킷은 일정한 속도로 보충된다.  

저장소가 레디스 데이터베이스와 같이 호스트 외부에 있으면, MSET 명령을 제공해 여러 키를 업데이트할 수 있지만, 단일 MSET 작업에서 업데이트할 수 있는 키 수에 제한이 있을 수 있다.  
시스템을 설계할 때 우리는 항상 합리적인 질문을 해야 하며 공식 문서조차 완전히 신뢰해서는 안 된다.  

업데이트 명령을 여러 요청으로 나눠야 한다면 각 요청은 리소스 오버헤드와 네트워크 지연을 초래한다.  


### 8.9.2 누수 버킷

요청이 도착할 때마다 버킷에 토큰을 추가한다.  
버킷이 가득 차면 요청이 거부되거나 속도가 제한된다.  

누수 버킷의 일반적인 구현은 고정 크기의 FIFO 큐를 사용하는 것이다.  


### 8.9.3 고정 윈도우 카운터

윈도우 간격은 고정돼 있다.  
윈도우가 지나면 모든 키가 만료된다.  


### 8.9.4 슬라이딩 윈도우 로그

슬라이딩 윈도우 로그는 각 요청 타임스탬프를 저장한다.  
새로운 요청이 들어오면 해당 타임스탬프를 추가하고 첫 번째 타임스탬프가 만료됐는지 확인한다.  
만료됐다면 이진 검색을 수행해 마지막으로 만료된 타임스탬프를 찾은 다음, 그 이전의 모든 타임스탬프를 제거한다.  


### 8.9.5 슬라이딩 윈도우 카운터

속도 제한 간격이 1시간이라면 1시간짜리 윈도우 하나 대신 1분짜리 윈도우 60개를 사용한다.  
현재 속도는 마지막 60개 윈도우를 합산해 결정한다.  


## 8.10 사이드카 패턴 적용

사용자 서비스 호스트는 속도 제한 정책을 조회하기 위해 속도 제한 서비스에 요청을 보낼 필요가 없어 네트워크 오버헤드를 줄일 수 있다.  


## 8.11 로깅, 모니터링, 경보

- 섀도 밴을 당했음에도 높은 비율로 요청을 보내는 경우
- DDoS


## 8.12 클라이언트 라이브러리로 기능 제공

클라이언트와 서버 간에 처리를 나누는 패턴은 모든 시스템에 일반화될 수 있다.  
하지만 이로 인해 클라이언트와 서버 간의 긴밀한 결합이 발생할 수 있는데, 이는 일반적으로 안티패턴으로 여겨진다.  






