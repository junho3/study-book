# 11 자동 완성/타입어헤드

자동 완성 시스템은 전 세계 수십억 명의 사용자가 입력한 문자열에서 데이터를 수집하고 이 데이터를 가중 트라이로 처리한다.  
자동 완성 시스템에 개인화와 머신러닝 요소를 추가할 수도 있다.  

## 11.1 자동 완성의 가능한 사용 사례

- 각 키 입력마다 자동 완성 제안 목록을 반환한다. 사용자가 제안을 선택하면 검색 서비스가 이를 수락하고 결과 목록을 반환한다.
  - 구글
  - 위키피디아
- 워드 프로세서가 자동 완성 제안을 제공할 수 있다.
  - 퍼지 매칭
- 코딩용 통합 개발 환경(IDE)에 자동 완성 기능이 있을 수 있다.

각 사용 사례에 따라 자동 완성 서비스는 서로 다른 데이터 소스와 아키텍처를 사용한다.

면접관이 '구글과 같은 일반 검색 앱용 자동 완성을 제공하는 시스템을 설계하라'와 같은 구체적인 질문을 하더라도 잠깐 동안 자동 완성 기능의 다른 용도에 대해 논의할 수 있다.  
질문을 넘어서 생각할 수 있고 성급하게 가정하거나 결론을 내리지 않는다는 것을 보여준다.

> IDE의 AI 플러그인도 짧은 시간 내에 서버와 통신하여 코드를 자동 완성 시키는건지? 


## 11.2 검색 vs. 자동 완성

자동 완성과 검색을 구별하고 요구사항을 혼동하지 않아야 한다.  

- 검색
  - 몇 초의 P99 지연 시간 허용
  - 높은 정확도 요구
- 자동 완성
  - 100ms의 P99
  - 정확도가 검색만큼 높지 않음


## 11.3 기능 요구사항

### 11.3.1 자동 완성 서비스의 범위

먼저 지원해야 할 사용 사례와 언어 등 범위의 세부 사항을 명확히 한다.


### 11.3.2 UX 세부 사항

- 문장 단위인지 개별 단어 단위인지
- 몇 자를 입력해야 자동 완성 제안이 표시되는지


### 11.3.3 검색 기록 고려

- 현재 입력만을 기반으로 할지
- 검색 기록과 다른 데이터 소스를 기반으로 할지


### 11.3.4 콘텐츠 조정과 공정성

- 부적절한 제안을 신고할 수 있는지
- 검색 빈도별 가중치를 고려해야 하는지


## 11.4 비기능적 요구사항

- 글로벌 사용자 기반이 사용할 수 있게 확장 가능해야 함
- 중요한 기능이 아니므로 내결함성은 양보 가능
- 높은 성능과 처리량. 0.5초 내 제안을 볼 수 있어야 함
- 일관성은 필요 없음
- 프라이버시와 보안
- 정확도


## 11.5 상위 수준 아키텍처 계획

- 데이터 수집
- 데이터 처리
- 처리된 데이터를 쿼리해 자동 완성 추천을 얻음

데이터 처리는 일반적으로 수집보다 리소스 집약적이다.  
수집은 요청을 받아들이고 기록하기만 하면 되며 트래픽 급증을 처리해야 한다.  
따라서 확장성을 높이기 위해 데이터 처리 시스템과 수집 시스템을 분리했다.  


## 11.6 가중치 트라이(Trie) 접근법과 초기 고수준 아키텍처

- 검색 서비스
  - 사용자가 검색 문자열 제출
- 공유 로깅 서비스
  - 자동 완성 추천을 도출하는 원시 데이터 소스
  - 사용자의 검색 쿼리를 기록
- 단어 처리 ETL 작업
- 가중치 트라이 생성기
- 자동 완성 서비스
    - 사용자에게 자동 완성 쿼리 제공

자동 완성 추천은 가중치 트라이를 사용해 생성된다.  
`B:4, A:4, T:22, Y:44`가 있을 때 `ba`를 입력하면 가중치가 높은 `bay`, `bat` 순서로 정렬


## 11.7 상세 구현

가중치 트라이 생성기는 일일 배치 ETL 파이프라인이 될 수 있다.  

단어 처리 ETL 작업과 가중치 트라이 생성기가 별도의 파이프라인 단계로 되어 있는 이유는 단어 처리 ETL 작업이 다른 여러 목적과 서비스에 유용할 수 있고, 별도의 단계로 구성하면 각각을 독립적으로 구현, 테스트, 유지보수 및 확장할 수 있기 때문이다.  

- 로깅 서비스의 검색 토픽에서 관련 로그를 가져와 임시 저장소에 저장
- 검색 문자열을 단어로 분리
- 부적절한 단어를 걸러냄
- 단어 수를 세어 단어 수 테이블에 기록. 필요한 정확도에 따라 모든 단어를 세거나 카운트-민 스케치와 같은 근사 알고리즘 사용
- 적절한 단어를 필터링하고 잘 알려지지 않은 인기 단어 기록
- 단어 수 테이블에서 가중치 트라이 생성
- 가중치 트라이를 백엔드 호스트로 전송

각 단계에서 이전 단계의 데이터베이스 저장소에서 데이터를 읽고 처리한 다음, 다음 단계에서 사용할 데이터베이스 저장소에 기록한다.  


### 11.7.1 각 단계는 독립적인 작업이어야 한다.

가중치 트라이 생성을 단일 작업으로 구현하고 모든 함수를 연결할 수 있다.  
이러한 접근 방식은 간단하지만 유지보수가 어렵다.  

가중치 트라이 생성에서 오류가 발생해 프로세스가 중단되면 전체 프로세스를 처음부터 다시 시작해야 한다.  
이러한 ETL 작업은 계산 집약적이며 완료하기까지 몇 시간이 걸릴 수 있으므로 이러한 접근 방식은 성능이 낮다.  
이러한 단계를 별도의 작업으로 구현하고 에어플로와 같은 작업 스케줄러 시스템을 사용해 이전 작업이 성공적으로 완료된 후에만 각 작업이 실행되게 해야 한다.  


### 11.7.2 일래스틱서치에서 HDFS로 관련 로그 가져오기

이 스크립트는 각 플롯폼의 병렬 처리 기능을 활용해야 한다.  
또한 분할 전략을 설명할 수도 있다.  


### 11.7.3 검색 문자열을 단어 및 다른 간단한 연산으로 분할하기

split 함수를 사용해 검색 문자열을 공백으로 분할한다.  
마침표, 대시, 쉼표와 같은 다른 구분자를 사용하는 등의 일반적인 문제도 고려해야할 수 있다.  


### 11.7.4 부적절한 단어 필터링하기

- 적절한 단어와 부적절한 단어 목록 관리하기
- 검색어 목록을 적절한 단어와 부적절한 단어 목록과 대조해 필터링하기

#### 단어 서비스

단어 서비스는 정렬된 적절한 단어나 부적절한 단어 목록을 반환하는 API 엔드포인트를 가진다.  
이 목록은 최대 몇 MB 크기이며 이진 검색을 허용하게 정렬돼 있다.  
크기가 작으므로 목록을 가져오는 모든 호스트는 단어 서비스를 사용할 수 없을 때를 대비해 이를 메모리에 캐시할 수 있다.  

#### 부적절한 단어 필터링하기

단어 수 계산 ETL 파이프라인은 단어 서비스에 부적절한 단어를 요청한 다음 이 목록을 HDFS 파일에 기록한다.  

스파크와 같은 분산 분석 엔진을 사용해 어떤 검색 문자열이 부적절한 단어인지 판단할 수 있다.  

면접에서는 SQL 쿼리에 30초 이내에 다음과 같은 중요한 로직을 적어 내려가야 한다.  

부적절한 단어 테이블이 작으므로 더 빠른 성능을 위해 맵 조인을 사용할 수 있다.
```
SELECT w.word
FROM words w LEFT OUTER JOIN inappropriate_words i ON i.word = w.word
WHERE i.word IS NULL
```


### 11.7.5 퍼지 매칭과 철자 교정

맞춤법 수정 단계는 여러 퍼지 매칭 알고리즘과 라이브러리 또는 서비스 중에 선택할 수 있어 요구사항에 맞게 최적화하기 위해 특정 알고리즘을 선택할 수 있으므로 독립적인 작업 단계다.  
이 단계를 분리하면 이 파이프라인 단계의 변경 사항이 다른 단계에 영향을 미치지 않으므로 퍼지 매칭을 위해 라이브러리나 서비스 간에 쉽게 전환할 수 있다.  


### 11.7.6 단어 수 세기


### 11.7.7 적절한 단어 필터링 하기

단어 수 세기 단계에서는 필터링할 단어 수를 크게 줄여야 한다.  


### 11.7.8 잘 알려지지 않은 인기 신조어 관리하기


### 11.7.9 가중치 트라이 생성 및 전달하기

이 목록은 단 몇 MB에 불과해 가중치 트라이를 단일 호스트에서 생성할 수 있다.  

트라이를 AWS S3와 같은 공유 객체 저장소나 MongoDB나 아마존 도큐먼트DB와 같은 문서 데이터베이스에 기록할 수 있다.  

호스트는 무작위 시간에 쿼리하거나 동시에 많은 요청이 객체 저장소에 부담을 주는 것을 방지하기 위해 지터를 사용해 동시에 쿼리하게 구성할 수 있다.  

공유 객체가 GB단위로 크다면 CDN에 배치하는 것을 고려해야 한다.  

작은 트라이의 또 다른 장점은 사용자가 검색 앱을 로드할 때 전체 트라이를 다운로드할 수 있어 트라이 조회가 서버 사이드가 아닌 클라이언트 사이드에서 이뤄진다는 점이다.  
이는 백엔드에 대한 요청 횟수를 크게 줄여 다음과 같은 이점이 있다.  
네트워크가 불안정하거나 느리면 사용자가 검색 문자열을 입력할 때 간헐적으로 제안을 받지 못할 수 있어 사용자 경험이 좋지 않다.  


## 11.8 샘플링 접근 방식

자동 완성에 높은 정확도가 필요하지 않다면 샘플링해야 한다.  

- 트라이를 훨씬 빠르게 생성할 수 있다.  
- 처리, 저장소, 네트워크를 포함한 하드웨어 리소스를 훨씬 적게 소비한다.  


## 11.9 저장소 요구사항 처리하기

10 억(사용자 수) * 10(하루 검색 횟수) * 20(평균 검색어 길이) = 200GB(검색 문자열)
200GB * 365(1년) = 73TB  
저장 비용을 줄이고 싶다면 다양한 방법을 고려할 수 있다.  

근사화와 샘플링으로 정확도 트레이드오프하는 것이다.  

다양한 기간으로 데이터를 집계하고, 입력 데이터를 롤업된 데이터로 덮어쓸 수 있다.  
언제든지 최대 하루치의 원시 데이터, 주별로 롤업된 4주치의 데이터, 월별로 롤업된 11개월치의 데이터를 보유한다.  


## 11.10 단일 단어 대신 구문 처리하기

트라이의 크기는 커지지만 가장 인기 있는 구문만 유지함으로써 여전히 몇 MB로 제한할 수 있다.  

### 11.10.1 자동 완성 추천의 최대 길이

최대 길이가 길수록 사용자에게 가장 유용하지만 비용과 성능 간의 트레이드 오프가 필요하다.  

사용자 검색 문자열 길이의 90번째 백분위수를 찾아 이를 최대 길이로 사용하는 것이다.  


### 11.10.2 부적절한 단어 방지하기

어려운 과제는 부적절한 단어뿐만 아니라 부적절한 구문을 필터링해야 한다는 점이다.  
이는 문제 공간의 방대함 때문에 구글조차도 완전한 해결책을 찾지 못 한 복잡한 문제다.  


## 11.11 로깅, 모니터링과 경보


## 11.12 기타 논의 가능한 주제

- 인기 있는 단어를 계속 세는 것은 계산 리소스의 낭비일 수 있다.
- 분산 로깅 서비스 설계하기
- 람다 아키텍처를 고려할 수 있다.
- 속도 제한기로 DoS 공격 방지
- 




