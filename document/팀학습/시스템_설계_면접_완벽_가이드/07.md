# 07 크레이그리스트 설계

## 7.1 사용자 스토리와 요구사항

- 게시물 요구사항
  - 제목
  - 설명 문단
  - 가격 (통화 변환 무시)
  - 위치
  - 최대 10장의 사진(각 1MB)
  - 동영상
  - 7일마다 게시물 갱신 가능
- 조회자 요구사항
  - 7일 동안 게시물 검색 (무한 스크롤)
  - 결과 필터
  - 세부 정보 조회
  - 이메일 등으로 게시자에게 연락
  - 사기 게시물 신고
- 비기능적 요구사항
  - 확장성: 단일 도시별 최대 1,000만명 사용자
  - 높은 성능: P99 1초
  - 보안(OpenID)
  - 게시물은 수동으로 생성
    - 1KB(게시물 용량) * 10만(평균 사용자) * 10(평균 게시물 작성량) = 10GB/일
  - 1주일 후 게시물 자동 삭제


## 7.2 API

- 게시물 관리 API
- 사용자 관리 API


## 7.3 SQL 데이터베이스 스키마

- Post: 비정규화 테이블로 JOIN 없이 게시물의 모든 세부 정보 조회 가능
- Storing images(이미지 저장): AWS S3


## 7.4 초기 고수준 아키텍처

- 사용자 인증 서비스와 게시물 객체 스토리지를 사용하는 모놀리스
- 클라이언트 프론트엔드 서비스, 백엔드 서비스, SQL 서비스, 객체 스토리지, 사용자 인증 서비스
- 로깅 서비스


## 7.5 모놀리스 아키텍처

모든 설계 결정이 트레이드오프에 관한 것임을 명심하고 이러한 설계를 제안하고 트레이드오프를 설명하는 것을 두려워하지 말아야 한다.  

핵심 설계 결정은 게시물의 사진을 포함해 게시물 웹페이지 전체를 객체 스토리지에 저장할 수 있는 것이다.  

특정 섹션을 제외하고는 정적페이지이다.  

- 주요 트레이드오프
  - HTML, CSS, Javascript가 모든 게시물에서 중복된다.
  - 네이티브 모바일 앱을 개발하면 브라우저 앱과 백엔드를 공유할 수 없다.
  - 게시물 분석은 HTML을 파싱해야 한다는 사소한 단점이 있다.

첫 번째 트레이드오프의 단점은 중복된 페이지 구성 요소를 저장하기 위해 추가 저장 공간이 필요하다는 점이다.  

> 중복된 페이지 구성 요소가 무슨 의미인지 이해 못 함


## 7.6 SQL 데이터베이스와 객체 스토리지 사용

이미지를 포함한 모든 데이터를 SQL 데이터베이스에 저장하고 객체 스토리지를 전혀 사용하지 않을 수도 있었다.  
그러나 이는 클라이언트가 백엔드 호스트를 통해 이미지 파일을 다운로드해야 함을 의미한다.  

- 백엔드 호스트 부담
- 이미지 다운로드 지연 시간 증가
- 갑작스러운 네트워크 이슈로 다운로드 실패 가능성 존재


## 7.7 마이그레이션은 번거롭다

SQL에 이미지 파일으 저장하는 것의 또 다른 단점은 향후 이를 객체 스토리지에 저장하게 마이그레이션해야 한다는 점이다.  

마이그레이션 작업이 버그나 네트워크 문제로 인해 갑자기 중단될 수 있으며 스크립트 실행을 다시 시작해야 할 수 있음을 예상해야 한다.  
새 데이터 스토리지에 중복 레코드가 쓰이는 것을 방지하기 위해 쓰기 엔드포인트는 멱등성을 가져야 한다.  
스크립트는 체크포인팅을 수행해야 하므로 이미 전송된 레코드를 다시 읽고 다시 쓰지 않는다.  

데이터 전송이 이 기술로 완료하기에 너무 크다면 데이터 센터 내에서 스크립트를 실행해야 한다.  
데이터가 여러 호스트에 분산돼 있다면 각 호스트에서 별도로 실행할 수 있다.  

쓰기 오류가 발생할 때마다 읽거나 쓰고 있는 레코드를 로깅하고, 다른 레코드를 계속 읽고 쓴다.  


데이터 마이그레이션이 복잡하고 비용이 많이 드는 작업이므로 가능하면 피해야 한다.  
처음부터 적절한 데이터 스토리지를 구축해야 한다.  


## 7.8 게시물 작성과 읽기

- 이미지 업로드에서 백엔드를 제외하는 방식
  - 적은 리소스
    - 이미지 파일 업로드가 백엔드를 거친다면 백엔드는 전체 스토리지와 함께 확장해야 한다.
  - 지연 시간 감소
- 이미지 업로드에서 백엔드를 포함하는 방식
  - 객체 스토리지에 인증, 권한 메커니즘을 구현할 필요가 없다
  - 객체 스토리지가 외부 네트워크에 노출되지 않는다
  - 일부나 모든 이미지를 성공적으로 업로드하지 않으면 게시물을 볼 수 없다

쓰기 요청의 최대 크기는 10MB를 약간 넘을 것이며, 이는 몇 초 내에 업로드할 수 있을 만큼 작다.  
하지만 이는 재시도 또한 더 비용이 많이 든다는 의미다.  


## 7.9 기능적 분할

확장의 첫 단계는 도시와 같은 지리상 지역별로 기능적 분할을 사용하는 것이다.  

크레이그리스트는 각 도시에 서브도메인을 할당해 이러한 지리적 분할을 수행한다.  

브라우저의 주소 표시줄에 서브도메인을 지정하는 대신 UI의 드롭다운 메뉴에서 도시를 선택할 수 있다.  


## 7.10 캐싱

레디스를 사용해 LRU 캐시를 구현할 수 있다.  


## 7.11 CDN


## 7.12 SQL 클러스터로 읽기 확장


## 7.13 쓰기 처리량 확장

SQL 서버의 ExecuteNonQuery는 초당 수천 건의 INSERT를 수행한다.  
개별 INSERT문 대신 배치 커밋을 사용하는 것으로, 각 INSERT 문 로그 플러시 오버헤드가 없어진다.  

### 카프카와 같은 메시지 브로커 사용

이 접근법의 주요 트레이드오프는 복잡성과 최종 일관성이다.  

- 카산드라
- NoSQL
- DDos 방지를 위한 Rate Limit


## 7.14 이메일 서비스


## 7.15 검색

Post 테이블에 일래스틱서치 인덱스를 생성한다.  

> DB 테이블에 일래스틱서치 인덱스를 생성한다는게 무엇인지?


## 7.16 오래된 게시물 제거

삭제 예정이었던 게시물이 며칠 동안 계속 접근 가능한 상태로 남아있어도 괜찮으므로 크론 작업으로 충분할 수 있으며, 에어플로를 사용하면 불필요한 복잡성이 생길 수 있다.  
에어플로와 같은 복잡한 워크플로 관리 플랫폼 대신 크론의 단순성을 선택하면 유지보수성이 향상된다.  

오래된 게시물을 제거하거나 오래된 데이터를 삭제하는 것의 장점은 다음과 같다.  
- 장점
  - 스토리지 프로비저닝과 유지보수 비용 절감
  - 읽기와 인덱싱 같은 데이터베이스 작업 속도 향상
  - 모든 데이터를 새 위치로 복사해야 하는 유지보수 작업의 속도가 빨라지고 복잡성이 낮아지며 비용이 줄어든다.
  - 프라이버시 보호 우려가 줄어들고 데이터 유출의 영향이 제한된다
- 단점
  - 데이터 분석과 유용한 인사이트 손실
  - 정부 규정으로 특정 기간 동안 데이터 보관이 필요할 수 있음
  - 조회자가 옛 게시물을 보고 있다고 착각할 수 있음
- 대안
  - 저비용 아카이브 하드웨어
  - AWS 글래시어


## 7.17 모니터링과 알람


## 7.18 아키텍처 논의 내용 요약


## 7.19 기타 논의 가능한 주제

### 7.19.1 게시물 신고

### 7.19.2 점진적 성능 저하

### 7.19.3 복잡성

크레이그리스트는 소규모 팀이 유지보수하기 쉽도록 단순성을 최우선으로 설계된 간단한 분류 광고 앱으로 설계 됐다.  

#### 종속성 최소화

라이브러리나 서비스에 의존성을 가진 모든 앱은 시간이 지남에 따라 자연스럽게 성능이 저하되며, 현재의 기능을 계속 제공하기 위해서는 개발자의 지속적인 유지보수가 필요하다.  

예를 들어, 크레이그리스트가 결제를 제공하지 않는 주요 이유는 결제를 처리하는 비즈니스 로직이 각 도시마다 다를 수 있기 때문이다.  

#### 클라우드 서비스 사용

#### 전체 웹페이지를 HTML 문서로 저장

게시물의 웹페이지를 데이터베이스나 CDN에 단일 HTML 문서로 저장할 수 있다.  
이 해결책은 모든 데이터베이스 항목에 중복된 HTML이 포함되므로 일부 저장 공간을 트레이드오프한다.  

이 접근 방식은 새 게시물에 필드를 추가하거나 제거하는 것도 덜 복잡하게 만든다.  

#### 관찰 가능성

- 로깅
- 모니터링
- 알림
- 자동화된 테스트
- 런북


## 7.19.4 품목 카테고리/태그

Post 테이블에는 쉼표로 구분된 태그 목록 열을 둘 수 있다.  
대안으로는 `post_tag`라는 연관/교차 테이블을 사용할 수 있다.  


## 7.19.5 분석과 추천

SQL 데이터베이스를 쿼리하고 다양한 지표 대시보드를 채우는 일일 배치 ETL 작업을 만들 수 있다.  


## 7.19.6 A/B 테스팅


## 7.19.7 구독과 저장된 검색


## 7.19.8 검색 서비스 중복 요청 허용

일래스틱서치는 빈번한 검색 요청을 캐싱하므로 같은 검색어로 빈번한 요청을 해도 많은 리소스를 낭비하지 않는다.  


## 7.19.9 검색 서비스에 중복 요청 피하기

```
SELECT DISTINCT LOWER(search_term)
FROM saved_search
WHERE timestamp >= UNIX_TIMESTAMP(DATEDD(CURDATE(), INTERVAL -1 DAY))
AND timestamp < UNIX_TEMSTAMP(CURDATE())
```
SQL 쿼리를 실행해 어제의 검색어를 중복 제거할 수 있다.  


## 7.19.10 속도 제한


## 7.19.11 대량의 게시물

여러 호스트에서 쿼리를 처리하고 조회자에게 반환하는 대신 단일 호스트에서 결과를 집계하는 설계는 지연 시간이 길고 비용이 많이 든다.  

- 게시물 보존 기간을 1주일로 정하고, 데이터 삭제
- 게시물에 저장되는 데이터의 양을 줄임
- 게시물 카테고리별로 테이블 관리
- 압축은 비용이 많이 들어 고려하지 않을 수 있음


## 7.19.12 지역 규정

국가, 주, 카운티, 도시 등 각 관할 구역은 크레이그리스트에 영향을 미치는 자체 규정을 가질 수 있다.  

정확한 요구사항을 설명해야 한다.  

더 나아가 이러한 규정이 많거나 자주 변경된다면 크레이그리스트 관리자가 규정을 구성할 수 있는 서비스를 만들고, 클라이언트가 이 서비스에 요청을 보내 어떤 HTML을 표시하거나 숨길지 결정해야 할 수 있다.  
이 서비스는 읽기 트래픽이 많고 쓰기 트래픽이 훨씬 적으므로 쓰기가 성공하게 CQRS 기법을 적용할 수 있다.  
관리자와 조회자를 위한 별도의 규정 서비스를 두고 주기적으로 동기화할 수 있다.  






